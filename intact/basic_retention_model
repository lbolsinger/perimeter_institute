from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score
import matplotlib.pyplot as plt

# Define features (X) and target (y)
X = df[["age", "sex", "marital_status", "accidents", "income", "treatment", "adjusted_premium"]].copy()
y = df["retained"]

# Encode 'sex' column
X['sex'] = X['sex'].map({'f': 0, 'm': 1})

# Encode 'marital_status' column
X['marital_status'] = X['marital_status'].map({'single': 0, 'married': 1})

# Split data into training and testing sets (optional but good practice)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize and train the Logistic Regression model
retention_model = LogisticRegression()
retention_model.fit(X_train, y_train)

# Predict retention probabilities on the test set
retention_probs = retention_model.predict_proba(X_test)[:, 1] # Get probability of the positive class (retained = True)

# Evaluate the model (optional) - using AUC as an example
auc_score = roc_auc_score(y_test, retention_probs)
print(f"AUC Score for the Retention Model: {auc_score:.4f}")

print("\nLogistic Regression Model for Retention Probability trained successfully.")
# You can now use the 'retention_model' to predict retention probability for new clients.

# Get the coefficients and feature names from the trained model
coefficients = retention_model.coef_[0]
feature_names = X_train.columns

# Create a dictionary of features and their coefficients
coef_dict = dict(zip(feature_names, coefficients))

# Sort coefficients for better visualization
sorted_coef = sorted(coef_dict.items(), key=lambda item: item[1], reverse=True)

# Separate features and coefficients for plotting
features = [item[0] for item in sorted_coef]
weights = [item[1] for item in sorted_coef]

# Create a bar plot of the coefficients
plt.figure(figsize=(10, 6))
plt.bar(features, weights, color='skyblue')
plt.xlabel('Features')
plt.ylabel('Coefficient Value')
plt.title('Logistic Regression Model Coefficients (Weight of Factors)')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()
